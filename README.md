
## 4.2日更新

*出于我认为当前的代码水平虽然成功实现了算法内容，但是可读性较差的缘故，我将要大举更改书写习惯和逻辑，以达到代码的清晰可读，甚至可以用代码解释注释的地步。
虽然我知道可能有点难度，但是我将会尝试。*

*我将会重新理清所有的逻辑，将每个步骤都完完整整、整整齐齐的呈现出来，增强可读性。*

## 下一步计划
1. 使用hadoop部署到集成服务器
2. 编写用户界面
3. 简化、优化函数

## 3.25日更新
1. 对频繁项对进行计数（设置阈值，得到最终的二元频繁桶）

## 3.18日更新
1. 第一次扫描完毕
2. 根据第一次扫描得到的的单项置信度得到频繁项
3. 将频繁项两两组队，产生项对
4. 将项对（i,j）与得到的位图中的频繁桶中的项对对比，只有项对（i,j）同时出现在两个哈希桶的频繁桶时，将其标记为频繁项对

## 3.16日更新
**细化整体流程：**
第一次扫描：
1. 获取单项计数值（置信度） [使用MapReduce](Map.py+Reduce.py)
2. 产生两两项对，并将其转化成整数（哈希要用）
3. 需要两个不同的哈希函数
4. 将产生的所有项对使用两个哈希函数分别哈希到两个哈希桶中，并且转换成位图（设置阈值，得到频繁桶）

第二次扫描：
1. 根据第一次扫描得到的的单项置信度得到频繁项
2. 将频繁项两两组队，产生项对
3. 将项对（i,j）与得到的位图中的频繁桶中的项对对比，只有项对（i,j）同时出现在两个哈希桶的频繁桶时，将其标记为频繁项对
4. 对频繁项对进行计数（设置阈值，得到最终的二元频繁项对）

**今日完成：**
1. 产生两两项对，将其转化为整数
2. 哈希位图
3. 开始正式项目

## 3.15日更新
1. 实现单元素map
    读取 data.txt 文件的数据
    输出map_output_1
2. 实现单元素reduce
    读取map_output_1
    输出reduce_output_1


# MapReduce-MultiHash
这是本人的毕设demo，实现mapreduce和multiHash算法分析销售数据，进行频繁项挖掘
预计实现的步骤如下：
1. 单元素Map
2. 单元素Reduce
3. 多元素Map
4. 多元素Reduce
5. 多哈希第一步
6. 多哈希第二步
7. 综合调试

